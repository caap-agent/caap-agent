{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c98cafa2d102cf12",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Common Parameters and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34aefeeb274175e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from element_type import TYPE_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2382e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXT = \".png\"\n",
    "INFO_EXT = \".json\"\n",
    "DEMO_RECORD_DIR = \"./_completed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30ac4967426de8bb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def search_filenames_having_both_of_image_and_json_information():\n",
    "    tgt_files = dict()\n",
    "    for episode in os.listdir(DEMO_RECORD_DIR):\n",
    "        episode_dir = os.path.join(DEMO_RECORD_DIR, episode)\n",
    "        \n",
    "        tgt_files[(episode, episode_dir)] = list()\n",
    "        ep_files = os.listdir(episode_dir)\n",
    "        for fpath in ep_files:\n",
    "            fname, ext = os.path.splitext(fpath)\n",
    "            if ext == INFO_EXT:\n",
    "                if fname + IMG_EXT in ep_files:\n",
    "                    tgt_files[(episode, episode_dir)].append(fname)\n",
    "    return tgt_files\n",
    "\n",
    "def _save_json(data, filepath):\n",
    "    with open(filepath, \"w\") as json_file:\n",
    "        json.dump(data, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466dd62ccfcfb06",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Duplicate Image Removal Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "782d3d510feb36bd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageChops\n",
    "\n",
    "def get_unique_images(tgt_files: dict):\n",
    "    epi_grp_files = dict()\n",
    "    for (episode, episode_dir), files in tgt_files.items():\n",
    "        grp_name = episode[:episode.find(\"_\")]\n",
    "        if grp_name not in epi_grp_files:\n",
    "            epi_grp_files[grp_name] = list()\n",
    "        epi_grp_files[grp_name].extend([os.path.join(episode_dir, f + IMG_EXT) for f in files])\n",
    "\n",
    "    print(\"\\n[Duplicated image removal]\")\n",
    "    compare_area_box = (0, 50, 160, 210)\n",
    "    unique_imgs = dict()\n",
    "    total_n_compares = 0\n",
    "    # Comparing images within a group and removing duplicate images.\n",
    "    for grp, files in epi_grp_files.items():\n",
    "        unique_imgs[grp] = list()\n",
    "        n_compares = 0\n",
    "        candidate_files = files.copy()\n",
    "        while candidate_files:\n",
    "            file1 = candidate_files.pop(0)\n",
    "            unique_imgs[grp].append(file1)\n",
    "            img1 = Image.open(file1).crop(compare_area_box)\n",
    "            file2_cands = candidate_files.copy()\n",
    "            diff_files_from_img1 = list()\n",
    "            while file2_cands:\n",
    "                file2 = file2_cands.pop(0)\n",
    "                img2 = Image.open(file2).crop(compare_area_box)\n",
    "                diff = ImageChops.difference(img1, img2)\n",
    "                n_compares += 1\n",
    "                if diff.getbbox():\n",
    "                    diff_files_from_img1.append(file2)\n",
    "            candidate_files = diff_files_from_img1.copy()\n",
    "\n",
    "        print(f\"- {grp}: {n_compares} compares, {len(unique_imgs[grp])} files survived out of {len(files)}\")\n",
    "        total_n_compares += n_compares\n",
    "\n",
    "    print(\n",
    "        f\"* total: {total_n_compares} compares, {sum([len(_files) for _files in unique_imgs.values()])} files survived out of {sum([len(_files) for _files in epi_grp_files.values()])}\")\n",
    "\n",
    "    return unique_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea2829d18814c3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837fca1ad6ae8d6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "tgt_files = search_filenames_having_both_of_image_and_json_information()\n",
    "\n",
    "unique_imgs = get_unique_images(tgt_files=tgt_files)\n",
    "\n",
    "_save_json(data=unique_imgs, filepath=\"./unique_imgs.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
